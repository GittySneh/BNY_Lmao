{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### creating environment variable!!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"]=\"AIzaSyAjEGxP6kezlPGu4NTFTId3KsYLldzCMro\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hkeW51wH4xWe"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20AbCF14HVNI",
        "outputId": "9e8bf8b7-21a6-4ad5-daa3-96b8e163873e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in c:\\users\\sneh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.24.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "CVdubeLiHZ_n"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as pdf:\n",
        "        for page in pdf:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "pdf_path = \"Sneh_220123062.pdf\"  # Change this to your PDF file path\n",
        "extracted_text = extract_text_from_pdf(pdf_path)\n",
        "#print(extracted_text)\n",
        "\n",
        "pdf_path =\"Sneh_220123062.pdf\"  # Change this to your PDF file path\n",
        "extracted_text2 = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "j2s2W2oo5Yup"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# Retrieve the API key from environment variables\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "peLaiSXW5Y5H"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "qZlEo8Hc8QGf"
      },
      "outputs": [],
      "source": [
        "#instruction1 = \" You are a brilliant resume summarizer .Summarize the following resume mentioning eductaion , skills , projects , achievement and work experience :-   \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "BL_ob6P39rwl"
      },
      "outputs": [],
      "source": [
        "instruction1 =''' You are a brilliant resume summarizer .Using the following example , summarize resumes in the exact format as given below.\n",
        " For example resume :-\n",
        " Udbhav Gupta +91-8107223633\n",
        "Roll No.:220101106 udbhavgupta0305@gmail.com\n",
        "B.Tech - Computer and Science Engineering udbhav@iitg.ac.in\n",
        "Indian Institute Of Technology, Guwahati linkedin.com/in/Udbhav Gupta\n",
        "Education\n",
        "Degree/Certificate Institute/Board CGPA/Percentage Year\n",
        "B.Tech. Major Indian Institute of Technology, Guwahati 8.86 (Current) 2022-Present\n",
        "Senior Secondary CBSE Board 92.2% 2022\n",
        "Secondary CBSE Board 94.8% 2020\n",
        "Projects\n",
        "• DocChain , A Complete Solution to Digital Identity Jan 2024 - Feb 2024\n",
        "First Prize Winner in Inter Hostel Technical Competition Github\n",
        "– Orchestrated backend architecture for blockchain-powered digital identity platform.\n",
        "– Implemented blockchain solutions for claims, voting, and property access management.\n",
        "– Leveraged Solidity, Third-Web SDK, and MetaMask Wallet API for seamless integration.\n",
        "• Live Points Leaderboard May 2023 - June 2023\n",
        "Coding Club , IIT Guwahati Github\n",
        "– Designed interactive leaderboard using JavaScript, HTML, and CSS for user-friendly contributor ranking.\n",
        "– Integrated live API data for real-time display of top contributors by points.\n",
        "• Diabetic Macular Edema Segmentation in OCT Images Oct. 2023 - Nov. 2023\n",
        "Coding Club , IIT Guwahati Github\n",
        "– Utilized UNet for diabetic macular edema in OCT images, enabling detailed analysis beyond classification.\n",
        "– Trained segmentation on 10 MATLAB files housing 61 retina images, advancing medical imaging insights.\n",
        "Skills\n",
        "• Programming: Python*, C/C++, Solidity*\n",
        "• Web Technologies: HTML ,CSS ,JavaScript*\n",
        "• Tools/Frameworks: Keras*, Tensorflow*, Pytorch*\n",
        "• Operating Systems:Windows, Linux* * Elementary proficiency\n",
        "Achievements\n",
        "• JEE Mains 2022, Secured an All India Rank of 371 among 1.2 million candidates appearing for the test 2022\n",
        "• JEE Advanced 2022, Secured an All India Rank of 514 out of 250,000 candidates appearing for the test 2022\n",
        "• KVPY SA 2020, Obtained the National research fellowship scholarship by securing an AIR of 871 2020\n",
        "• KVPY SX 2021, Secured a CRL Rank of 993 among 100,000 candidates appearing for the test 2021\n",
        "• Codeforces, Secured World Rank of 430 in Round 918 - Highest Rating 1501 (Specialist) 2023\n",
        "• Reliance Foundation Undergraduate Scholarship, Awardee for Academic Excellence 2023\n",
        "• ICPC-de-Tryst , IIT Delhi, Attained 68th rank in a competitive programming competition. 2024\n",
        "• STSE 2020, Attained 11th rank in the State examination administered by the Rajasthan Board. 2020\n",
        "• ML Hackathon , IITG.Ai, Secured third position among 155 candidates in the ML focused Hackathon. 2023\n",
        "• Kriti CP Competition, Awarded Gold Medal for achieving 1st place in the competitive programming event 2023\n",
        "• Kriti CTF Competition, Secured 1st rank in the Cybersecurity event 2023\n",
        "Key courses taken\n",
        "–Mathematics: Linear Algebra, Basic Calculus, Probability & Random Processes\n",
        "–Computer Science: Data Structures and Algorithms, Introduction to Computing\n",
        "–MOOC’s: Neural Networks and Deep Learning , Convolutional Neural Networks by Deep Learning.AI\n",
        "Positions of Responsibility\n",
        "– Coordinator, Coding Club, IIT Guwahati July. 2023 - July. 2024\n",
        "∗ Conducted various workshops and took part in projects related to ML and Web Development\n",
        "– Associate, Consulting and Analytics Club, IIT Guwahati May. 2023 - May. 2024\n",
        "∗ Contributed in organizing workshops and discussions centered around Consulting and Analytics within the club\n",
        "\n",
        "Summary :-\n",
        "\n",
        "Name :- Udbhav Gupta\n",
        "Degree:- B.Tech - Computer and Science Engineering\n",
        "College:- Indian Institute Of Technology, Guwahati\n",
        "**Education:**\n",
        "CGPA :- 8.86 (Current)\n",
        "Senior Secondary CBSE Board 92.2% 2022\n",
        "Secondary CBSE Board 94.8% 2020\n",
        "**Projects:** Blockchain digital identity platform, Interactive leaderboard, Diabetic macular edema segmentation\n",
        "**Skills:** Python, C/C++, Solidity, HTML, CSS, JavaScript, Keras, Tensorflow, Pytorch\n",
        "**Achievements:**\n",
        "- JEE Mains :- AIR 371/1.2M\n",
        "- JEE Advanced :- AIR 514/250K\n",
        "- KVPY SA :- AIR 871\n",
        "- KVPY SX :- CRL 993\n",
        "- Codeforces :- World Rank 430, Rating 1501\n",
        "- Scholarship :- Reliance Foundation\n",
        "- ICPC-de-Tryst :- Rank 68\n",
        "- Hackathon :- ML Hackathon 3rd Place\n",
        "\n",
        "**Positions of Responsibility: **\n",
        "- Coordinator, Coding Club, IIT Guwahati ,\n",
        "- Associate, Consulting and Analytics Club\n",
        "\n",
        "Resume :-\n",
        " '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "dfb4_SwJ7HTV"
      },
      "outputs": [],
      "source": [
        "companyCriteria=\"\"\"\"\"\"\n",
        "#input should be provided here\n",
        "jobProfile=\"\"\"Technical\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Bup_1QjY5Y8v"
      },
      "outputs": [],
      "source": [
        "resumeSummary1 = model.generate_content(instruction1 + extracted_text)\n",
        "resumeSummary2 = model.generate_content(instruction1 + extracted_text2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vGTNYS_C7jaw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Summary:**\n",
            "\n",
            "**Name:** Sneh Dadhania\n",
            "**Degree:** B.Tech - Mathematics and Computing\n",
            "**College:** Indian Institute Of Technology, Guwahati\n",
            "**Education:**\n",
            "CGPA: 8.22 (Current)\n",
            "Senior Secondary: CBSE Board, 94.8% (2022)\n",
            "Secondary: CBSE Board, 93.4% (2020)\n",
            "**Projects:**\n",
            "- MathQuery Resolver\n",
            "- Generic Data Encryption Service\n",
            "- Airline Ticket Booking Website\n",
            "- Options and its Pricing Models\n",
            "**Skills:**\n",
            "- Programming languages: C, C++, Python, JavaScript\n",
            "- Database: MySQL, MongoDB, Redis\n",
            "- Backend and Frontend: HTML, CSS, Node.js, Express.js\n",
            "- Miscellaneous: Postman, Swagger, Langchain, LaTeX\n",
            "**Achievements:**\n",
            "- JEE Advanced: AIR 893\n",
            "- JEE Mains: AIR 2403\n",
            "- CodeChef: Global Rank 124 in Starters 140\n",
            "- Codeforces: Global Rank 1159 in Round 944\n"
          ]
        }
      ],
      "source": [
        "#print(ressume)\n",
        "print(resumeSummary1.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "_AyGYxVYAJd9"
      },
      "outputs": [],
      "source": [
        "if (jobProfile == \"Technical\"):\n",
        "\n",
        "  analyzePrompt = \"\"\"\n",
        "  Input has summarisations of resumes of two candidates for a job. You are an impeccable resume comparer who quantifies the given resumes on the basis of some standards and gives them a score out of 100\n",
        "  2)return in json format number of tuples equal to the number of resumes provided with their respective values.\n",
        "  VALUES AT THE SAME INDEX IN ALL TUPLES MUST POINT AT THE SAME SKILL, these values are some numbers\n",
        "  3)The tuples returned should have the identification skill and their specific values\n",
        "  4)A tuple should contain jee mains rank ,jee advanced rank, codeforces rating,codeforces contest rank,codechef rating, cpi, 12th board percentage,\n",
        "  10th board percentage,number of internships,number of research internships,total experience for a technical resume\n",
        "  The above provided set of attributes should be there in the returned tuples always\n",
        "  5)Each indice of the tuples should point to the same skill\n",
        "  7)Return n tuples where n = number of resumes provided\n",
        "  8)Your motive is the list all the quantifiable skills in a tuple format , assign each of the skillset the explicit value as mentioned in the resume\n",
        "  assign the value null, wherever required (an quanttifiable value that is a number)\n",
        "  9)If some resume hasnt mentioned the codechef rating,you can assign the value null\n",
        "  and assign them with null if not present in the given resume , or with the provided value in the resume\n",
        "  10)Only assign mathematically comparable values in the tuples, the value of each tuple should be mathematical value, not a string\n",
        "  11)You cant provide the value of some other index to some other index, for example dont add the rating/rank of two different competitions or\n",
        "  platforms at the same index, create new index and provide the value at the new index and assign it None for the resumes which dont have it\n",
        "  12)Return the same number of tuples as the number of resumes provided\n",
        "  13)same set of attributes for each resume should be returned\n",
        "  14) These are the basic attributes which each tuple should always contain, further attributes to be added will also be mentioned in the\n",
        "  next queries, which should be added, accordingly with None values if not present or the provided mathematical value(or count) in the resume\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "if (jobProfile == \"Financial\"):\n",
        "  analyzePrompt = \"\"\"\n",
        "  Input contains summaries of resumes of several candidates for a financial position. You are an expert resume comparer who quantifies the given resumes on the basis of industry standards and assigns a score out of 100.\n",
        "  2) Return in JSON format a number of tuples equal to the number of resumes provided, each containing their respective values.\n",
        "    VALUES AT THE SAME INDEX IN ALL TUPLES MUST POINT AT THE SAME SKILL; these values are numerical.\n",
        "  3) The tuples returned should have the identification skill and their specific values.\n",
        "  4) A tuple should contain MBA entrance exam score (if applicable), CFA level passed, GMAT score,\n",
        "  financial modeling certification score, number of years in financial sector, number of internships, number of finance-specific\n",
        "  research projects, total experience in finance, 12th board percentage, 10th board percentage, and CPI.\n",
        "  The above-provided set of attributes should always be present in the returned tuples.\n",
        "  5) Each index of the tuples should point to the same skill across all resumes.\n",
        "  7) Return n tuples where n equals the number of resumes provided.\n",
        "  8) Your motive is to list all the quantifiable skills in a tuple format, assign each of the skill sets the explicit value as mentioned in the resume.\n",
        "    Assign the value None wherever required (any quantifiable value that is a number).\n",
        "  9) If some resume hasn't mentioned the GMAT score, you can assign the value None.\n",
        "    Assign them with null if not present in the given resume, or with the provided value in the resume.\n",
        "  10) Only assign mathematically comparable values in the tuples; the value of each tuple should be a mathematical value, not a string.\n",
        "  11) You can't provide the value of some other index to some other index; for example, don’t add the score of two different exams at the same index. Create a new index and provide the value at the new index and assign it null for the resumes which don’t have it.\n",
        "  12) Return the same number of tuples as the number of resumes provided.\n",
        "  13) The same set of attributes for each resume should be returned.\n",
        "  14) These are the basic attributes which each tuple should always contain; further attributes to be added will also be mentioned in the next queries, which should be added accordingly with null values if not present or the provided mathematical value (or count) in the resume.\n",
        "  \"\"\"\n",
        "\n",
        "if (jobProfile == \"Designer\"):\n",
        "  analyzePrompt = \"\"\"\n",
        "  Input contains summaries of resumes of several candidates for a design position. You are an expert resume comparer who quantifies the given resumes based on industry standards and assigns a score out of 100.\n",
        "  2) Return in JSON format a number of tuples equal to the number of resumes provided, each containing their respective values.\n",
        "    VALUES AT THE SAME INDEX IN ALL TUPLES MUST POINT AT THE SAME SKILL; these values are numerical.\n",
        "  3) The tuples returned should have the identification skill and their specific values.\n",
        "  4) A tuple should contain scores or levels for design-related qualifications including Adobe Creative Suite proficiency score, UX/UI certification score, graphic design portfolio rating, number of design projects completed, number of design internships, number of design awards won, total experience in design, 12th board percentage, 10th board percentage, and CPI.\n",
        "    The above-provided set of attributes should always be present in the returned tuples.\n",
        "  5) Each index of the tuples should point to the same skill across all resumes.\n",
        "  7) Return n tuples where n equals the number of resumes provided.\n",
        "  8) Your motive is to list all the quantifiable skills in a tuple format, assign each of the skill sets the explicit value as mentioned in the resume.\n",
        "    Assign the value null wherever required (any quantifiable value that is a number).\n",
        "  9) If a resume hasn't mentioned the UX/UI certification score, you can assign the value None.\n",
        "    Assign them with null if not present in the given resume, or with the provided value in the resume.\n",
        "  10) Only assign mathematically comparable values in the tuples; the value of each tuple should be a mathematical value, not a string.\n",
        "  11) You can't provide the value of some other index to some other index; for example, don’t add the proficiency score of one software as a substitute for another. Create a new index and provide the value at the new index and assign it null for the resumes which don’t have it.\n",
        "  12) Return the same number of tuples as the number of resumes provided.\n",
        "  13) The same set of attributes for each resume should be returned.\n",
        "  14) These are the basic attributes which each tuple should always contain; further attributes to be added will also be mentioned in the next queries, which should be added accordingly with null values if not present or the provided mathematical value (or count) in the resume.\n",
        "  \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "mWOlQ2adMrkx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[\n",
            "  {\n",
            "    \"jee_mains_rank\": 2403,\n",
            "    \"jee_advanced_rank\": 893,\n",
            "    \"codeforces_rating\": null,\n",
            "    \"codeforces_contest_rank\": null,\n",
            "    \"codechef_rating\": 124,\n",
            "    \"cpi\": 8.22,\n",
            "    \"12th_board_percentage\": 94.8,\n",
            "    \"10th_board_percentage\": 93.4,\n",
            "    \"number_of_internships\": null,\n",
            "    \"number_of_research_internships\": null,\n",
            "    \"total_experience\": null\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content([resumeSummary1.text, resumeSummary2.text, analyzePrompt, companyCriteria])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "7yg8ZRn0Mmse"
      },
      "outputs": [],
      "source": [
        "template = {\n",
        "    \"jee_mains_rank\": {\"weight\": 0.05, \"default\":  2000, \"prefers_higher\": False},\n",
        "    \"jee_advanced_rank\": {\"weight\": 0.05, \"default\": 2000, \"prefers_higher\": False},\n",
        "    \"codeforces_rating\": {\"weight\": 0.15, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"codeforces_contest_rank\": {\"weight\": 0.1, \"default\": 0, \"prefers_higher\": False},\n",
        "    \"codechef_rating\": {\"weight\": 0.1, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"cpi\": {\"weight\": 0.2, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"board_12th_percentage\": {\"weight\": 0.05, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"board_10th_percentage\": {\"weight\": 0.05, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"number_of_projects\": {\"weight\": 0.1, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"number_of_internships\": {\"weight\": 0.05, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"number_of_research_experience\": {\"weight\": 0.1, \"default\": 0, \"prefers_higher\": True},\n",
        "    \"total_experience\": {\"weight\": 0.1, \"default\": 0, \"prefers_higher\": True}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Fs0a2QxR9YZ7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def create_scores_dict(json_str, template):\n",
        "    def normalize_entry(entry, max_values, min_values, template):\n",
        "        normalized_entry = {}\n",
        "        for key in template.keys():\n",
        "            value = entry.get(key)\n",
        "            if value is not None:\n",
        "                if template[key]['prefers_higher']:\n",
        "                    if max_values[key] == min_values[key]:\n",
        "                        normalized_entry[key] = 1\n",
        "                    else:\n",
        "                        normalized_entry[key] = (value - min_values[key]) / (max_values[key] - min_values[key])\n",
        "                else:\n",
        "                    if max_values[key] == min_values[key]:\n",
        "                        normalized_entry[key] = 1\n",
        "                    else:\n",
        "                        normalized_entry[key] = 1 - (value - min_values[key]) / (max_values[key] - min_values[key])\n",
        "            else:\n",
        "                normalized_entry[key] = template[key]['default']\n",
        "        return normalized_entry\n",
        "\n",
        "    def calculate_total_score(normalized_entry, template):\n",
        "        total_score = 0\n",
        "        for key, value in normalized_entry.items():\n",
        "            total_score += value * template[key]['weight']\n",
        "        return total_score\n",
        "\n",
        "    def format(input_string):\n",
        "      # Define a regular expression pattern to match non-keyboard characters\n",
        "      pattern = r'[^\\x20-\\x7E]'\n",
        "      # Use the re.sub() function to replace all non-keyboard characters with an empty string\n",
        "      cleaned_string = re.sub(pattern, '', input_string)\n",
        "      return cleaned_string\n",
        "      # Initialize scores dictionary\n",
        "\n",
        "    scores_dict = {}\n",
        "    #print(json_str)\n",
        "\n",
        "    json_str = json_str[json_str.find(\"[\"):json_str.find(\"]\") + 1].strip()\n",
        "    #print(json_str)\n",
        "\n",
        "    json_str = format(json_str)\n",
        "\n",
        "    #print(json_str)\n",
        "\n",
        "    json_str = json_str.replace(\"\\'\", \"\")\n",
        "\n",
        "    #print(json_str)\n",
        "\n",
        "    data = json.loads(json_str)\n",
        "\n",
        "    # Find the maximum and minimum values for each attribute across all entries\n",
        "    max_values = {key: float('-inf') for key in template}\n",
        "    min_values = {key: float('inf') for key in template}\n",
        "    for entry in data:\n",
        "        for key, value in entry.items():\n",
        "            if key in template and value is not None:\n",
        "                max_values[key] = max(max_values[key], value)\n",
        "                min_values[key] = min(min_values[key], value)\n",
        "\n",
        "    # Normalize each entry using the maximum values and calculate total scores\n",
        "    for idx, entry in enumerate(data, start=1):\n",
        "        normalized_entry = normalize_entry(entry, max_values, min_values, template)\n",
        "        total_score = calculate_total_score(normalized_entry, template)\n",
        "        scores_dict[idx] = total_score\n",
        "\n",
        "    return scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GwoOtsWjcNRk"
      },
      "outputs": [],
      "source": [
        "test = response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "PhnixUOQ9YTc"
      },
      "outputs": [],
      "source": [
        "#map_list = json.loads(der)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "NdMini1MdYvc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1: 0.4}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "create_scores_dict(test, template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Client Name</th>\n",
              "      <th>Bank Name</th>\n",
              "      <th>Account Number</th>\n",
              "      <th>Transaction Date</th>\n",
              "      <th>Credit/Debit</th>\n",
              "      <th>Description</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Client Name, Bank Name, Account Number, Transaction Date, Credit/Debit, Description , Amount, Balance]\n",
              "Index: []"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assuming iss point tak ek pandas dataframe hai\n",
        "import pandas as pd\n",
        "dict = {\"Client Name\": [], \"Bank Name\": [], \"Account Number\": [], \"Transaction Date\":[],\"Credit/Debit\": [] ,\"Description \":[], \"Amount\":[],\"Balance\":[]}\n",
        "df = pd.DataFrame(dict)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create/connect to a database\n",
        "conn = sqlite3.connect('financial_data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a table structure for extracted data\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS transactions (\n",
        "                     id INTEGER PRIMARY KEY,\n",
        "                     client_name TEXT,\n",
        "                     bank_name TEXT,\n",
        "                     account_number TEXT,\n",
        "                     transaction_date TEXT,\n",
        "                     credit_debit TEXT,\n",
        "                     description TEXT,\n",
        "                     amount REAL,\n",
        "                     balance REAL\n",
        "                  )''')\n",
        "\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_name</th>\n",
              "      <th>bank_name</th>\n",
              "      <th>account_number</th>\n",
              "      <th>transaction_date</th>\n",
              "      <th>credit_debit</th>\n",
              "      <th>description</th>\n",
              "      <th>amount</th>\n",
              "      <th>balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dennis Elliott</td>\n",
              "      <td>Ramirez-Bryant</td>\n",
              "      <td>2555189089</td>\n",
              "      <td>2022-11-11</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Model kid business front.</td>\n",
              "      <td>9735.38</td>\n",
              "      <td>5665.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jennifer Garcia</td>\n",
              "      <td>Yates-Williams</td>\n",
              "      <td>4146518100</td>\n",
              "      <td>2024-05-30</td>\n",
              "      <td>Credit</td>\n",
              "      <td>Cup ready wall fund.</td>\n",
              "      <td>9895.91</td>\n",
              "      <td>36917.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Robert Parker</td>\n",
              "      <td>Mcintyre and Sons</td>\n",
              "      <td>3923789319</td>\n",
              "      <td>2023-02-12</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Message administration risk worker already.</td>\n",
              "      <td>6401.98</td>\n",
              "      <td>43218.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shawn Brown</td>\n",
              "      <td>Duarte Ltd</td>\n",
              "      <td>7951492869</td>\n",
              "      <td>2023-11-07</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Follow will at expert.</td>\n",
              "      <td>3827.66</td>\n",
              "      <td>49462.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lindsey Mckinney</td>\n",
              "      <td>Roth Group</td>\n",
              "      <td>7905036678</td>\n",
              "      <td>2023-02-03</td>\n",
              "      <td>Credit</td>\n",
              "      <td>Reason condition until.</td>\n",
              "      <td>2493.21</td>\n",
              "      <td>37711.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Jason Lawrence</td>\n",
              "      <td>Evans, Tran and Henderson</td>\n",
              "      <td>1096520923</td>\n",
              "      <td>2024-05-09</td>\n",
              "      <td>Credit</td>\n",
              "      <td>Former tend quite point box treat.</td>\n",
              "      <td>6054.51</td>\n",
              "      <td>99455.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>April Thompson</td>\n",
              "      <td>Wall, Wade and Gonzalez</td>\n",
              "      <td>7401924323</td>\n",
              "      <td>2024-04-28</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Ask realize ago management example center.</td>\n",
              "      <td>4819.74</td>\n",
              "      <td>42437.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Jesse Kelly</td>\n",
              "      <td>Williams-Wood</td>\n",
              "      <td>5579933434</td>\n",
              "      <td>2024-09-20</td>\n",
              "      <td>Debit</td>\n",
              "      <td>Television commercial approach experience parent.</td>\n",
              "      <td>2698.92</td>\n",
              "      <td>72650.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Danielle Sampson</td>\n",
              "      <td>Padilla Group</td>\n",
              "      <td>1767795832</td>\n",
              "      <td>2023-08-12</td>\n",
              "      <td>Debit</td>\n",
              "      <td>North catch likely best.</td>\n",
              "      <td>7242.01</td>\n",
              "      <td>14239.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Christopher Thomas</td>\n",
              "      <td>Davidson, Hester and Hernandez</td>\n",
              "      <td>7015871966</td>\n",
              "      <td>2022-11-16</td>\n",
              "      <td>Debit</td>\n",
              "      <td>My test approach individual I visit well.</td>\n",
              "      <td>6590.42</td>\n",
              "      <td>27102.51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          client_name                       bank_name  account_number  \\\n",
              "0      Dennis Elliott                  Ramirez-Bryant      2555189089   \n",
              "1     Jennifer Garcia                  Yates-Williams      4146518100   \n",
              "2       Robert Parker               Mcintyre and Sons      3923789319   \n",
              "3         Shawn Brown                      Duarte Ltd      7951492869   \n",
              "4    Lindsey Mckinney                      Roth Group      7905036678   \n",
              "5      Jason Lawrence       Evans, Tran and Henderson      1096520923   \n",
              "6      April Thompson         Wall, Wade and Gonzalez      7401924323   \n",
              "7         Jesse Kelly                   Williams-Wood      5579933434   \n",
              "8    Danielle Sampson                   Padilla Group      1767795832   \n",
              "9  Christopher Thomas  Davidson, Hester and Hernandez      7015871966   \n",
              "\n",
              "  transaction_date credit_debit  \\\n",
              "0       2022-11-11        Debit   \n",
              "1       2024-05-30       Credit   \n",
              "2       2023-02-12        Debit   \n",
              "3       2023-11-07        Debit   \n",
              "4       2023-02-03       Credit   \n",
              "5       2024-05-09       Credit   \n",
              "6       2024-04-28        Debit   \n",
              "7       2024-09-20        Debit   \n",
              "8       2023-08-12        Debit   \n",
              "9       2022-11-16        Debit   \n",
              "\n",
              "                                         description   amount   balance  \n",
              "0                          Model kid business front.  9735.38   5665.78  \n",
              "1                               Cup ready wall fund.  9895.91  36917.12  \n",
              "2        Message administration risk worker already.  6401.98  43218.68  \n",
              "3                             Follow will at expert.  3827.66  49462.30  \n",
              "4                            Reason condition until.  2493.21  37711.95  \n",
              "5                 Former tend quite point box treat.  6054.51  99455.35  \n",
              "6         Ask realize ago management example center.  4819.74  42437.70  \n",
              "7  Television commercial approach experience parent.  2698.92  72650.87  \n",
              "8                           North catch likely best.  7242.01  14239.71  \n",
              "9          My test approach individual I visit well.  6590.42  27102.51  "
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Step 1: Generate random data\n",
        "def generate_random_data(num_rows=10):\n",
        "    data = {\n",
        "        'client_name': [fake.name() for _ in range(num_rows)],\n",
        "        'bank_name': [fake.company() for _ in range(num_rows)],\n",
        "        'account_number': [fake.random_number(digits=10) for _ in range(num_rows)],\n",
        "        'transaction_date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(num_rows)],\n",
        "        'credit_debit': [np.random.choice(['Credit', 'Debit']) for _ in range(num_rows)],\n",
        "        'description': [fake.text(max_nb_chars=50) for _ in range(num_rows)],\n",
        "        'amount': [round(np.random.uniform(100, 10000), 2) for _ in range(num_rows)],\n",
        "        'balance': [round(np.random.uniform(1000, 100000), 2) for _ in range(num_rows)],\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "data = generate_random_data(10)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'sqlite3' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m     18\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 20\u001b[0m \u001b[43mcreate_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Step 3: Insert DataFrame data into the SQLite database\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert_data_into_db\u001b[39m(df):\n",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m, in \u001b[0;36mcreate_table\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_table\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43msqlite3\u001b[49m\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinancial_data.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m      6\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mCREATE TABLE IF NOT EXISTS transactions (\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m                        id INTEGER PRIMARY KEY AUTOINCREMENT,\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m                        client_name TEXT,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m                        balance REAL\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m                    )\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'sqlite3' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 2: Create transactions table in SQLite if it doesn't exist\n",
        "def create_table():\n",
        "    conn = sqlite3.connect('financial_data.db')\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute('''CREATE TABLE IF NOT EXISTS transactions (\n",
        "                        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                        client_name TEXT,\n",
        "                        bank_name TEXT,\n",
        "                        account_number TEXT,\n",
        "                        transaction_date TEXT,\n",
        "                        credit_debit TEXT,\n",
        "                        description TEXT,\n",
        "                        amount REAL,\n",
        "                        balance REAL\n",
        "                    )''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "create_table()\n",
        "\n",
        "# Step 3: Insert DataFrame data into the SQLite database\n",
        "def insert_data_into_db(df):\n",
        "    conn = sqlite3.connect('financial_data.db')\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    for _, row in df.iterrows():\n",
        "        cursor.execute('''INSERT INTO transactions (client_name, bank_name, account_number, \n",
        "                                                    transaction_date, credit_debit, description, \n",
        "                                                    amount, balance)\n",
        "                          VALUES (?, ?, ?, ?, ?, ?, ?, ?)''', \n",
        "                       (row['client_name'], row['bank_name'], row['account_number'], \n",
        "                        row['transaction_date'], row['credit_debit'], row['description'], \n",
        "                        row['amount'], row['balance']))\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# insert_data_into_db(data)\n",
        "\n",
        "# Step 4: Fetch and display data from the database\n",
        "def fetch_data_from_db():\n",
        "    conn = sqlite3.connect('financial_data.db')\n",
        "    query = \"SELECT * FROM transactions\"\n",
        "    df = pd.read_sql(query, conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "# Fetch and display the data\n",
        "data_from_db = fetch_data_from_db()\n",
        "print(data_from_db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-20 06:17:28.983 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:28.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:28.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:28.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:28.991 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:28.993 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:28.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:29.003 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-20 06:17:29.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "from faker import Faker\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Step 1: Generate random data (for testing purposes if needed)\n",
        "def generate_random_data(num_rows=10):\n",
        "    data = {\n",
        "        'client_name': [fake.name() for _ in range(num_rows)],\n",
        "        'bank_name': [fake.company() for _ in range(num_rows)],\n",
        "        'account_number': [fake.random_number(digits=10) for _ in range(num_rows)],\n",
        "        'transaction_date': [fake.date_between(start_date='-2y', end_date='today') for _ in range(num_rows)],\n",
        "        'credit_debit': [np.random.choice(['Credit', 'Debit']) for _ in range(num_rows)],\n",
        "        'description': [fake.text(max_nb_chars=50) for _ in range(num_rows)],\n",
        "        'amount': [round(np.random.uniform(100, 10000), 2) for _ in range(num_rows)],\n",
        "        'balance': [round(np.random.uniform(1000, 100000), 2) for _ in range(num_rows)],\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Step 2: Create transactions table in SQLite if it doesn't exist\n",
        "def create_table():\n",
        "    conn = sqlite3.connect('financial_data.db')\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    cursor.execute('''CREATE TABLE IF NOT EXISTS transactions (\n",
        "                        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                        client_name TEXT,\n",
        "                        bank_name TEXT,\n",
        "                        account_number TEXT,\n",
        "                        transaction_date TEXT,\n",
        "                        credit_debit TEXT,\n",
        "                        description TEXT,\n",
        "                        amount REAL,\n",
        "                        balance REAL\n",
        "                    )''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "create_table()\n",
        "\n",
        "# Step 3: Insert DataFrame data into the SQLite database\n",
        "def insert_data_into_db(df):\n",
        "    conn = sqlite3.connect('financial_data.db')\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    for _, row in df.iterrows():\n",
        "        cursor.execute('''INSERT INTO transactions (client_name, bank_name, account_number, \n",
        "                                                    transaction_date, credit_debit, description, \n",
        "                                                    amount, balance)\n",
        "                          VALUES (?, ?, ?, ?, ?, ?, ?, ?)''', \n",
        "                       (row['client_name'], row['bank_name'], row['account_number'], \n",
        "                        row['transaction_date'], row['credit_debit'], row['description'], \n",
        "                        row['amount'], row['balance']))\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Step 4: Fetch and display data from the database\n",
        "def fetch_data_from_db():\n",
        "    conn = sqlite3.connect('financial_data.db')\n",
        "    query = \"SELECT * FROM transactions\"\n",
        "    df = pd.read_sql(query, conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "# Step 5: Upload PDF and Extract Data\n",
        "def upload_and_extract_data():\n",
        "    st.header(\"Upload a PDF file\")\n",
        "    uploaded_file = st.file_uploader(\"Choose a PDF file\", type=\"pdf\")\n",
        "    \n",
        "    if uploaded_file is not None:\n",
        "        # Simulate PDF processing (Replace with your data extraction code)\n",
        "        st.info(\"Processing the PDF file...\")\n",
        "        \n",
        "        # Extract data (replace with your actual data extraction logic)\n",
        "        # DATA EXTRACTION CODE HERE\n",
        "        \n",
        "        # For testing, we generate random data (replace with your extracted data)\n",
        "        data = generate_random_data(5)  # replace 5 with the number of rows extracted\n",
        "        \n",
        "        # Display the extracted data\n",
        "        st.dataframe(data)\n",
        "        \n",
        "        # Save to database\n",
        "        if st.button(\"Save Extracted Data to Database\"):\n",
        "            insert_data_into_db(data)\n",
        "            st.success(\"Data saved to the database successfully!\")\n",
        "        \n",
        "        return data\n",
        "\n",
        "# Step 6: Display and Edit Data\n",
        "def display_and_edit_data():\n",
        "    data_from_db = fetch_data_from_db()\n",
        "    if len(data_from_db) > 0:\n",
        "        st.subheader(\"Edit Data\")\n",
        "        st.dataframe(data_from_db)\n",
        "        \n",
        "        selected_id = st.number_input('Enter the row ID to edit', min_value=1, max_value=len(data_from_db), step=1)\n",
        "        \n",
        "        if st.button(\"Update Selected Row\"):\n",
        "            st.write(f\"Updating row ID: {selected_id}\")\n",
        "            # Update logic goes here (e.g., pop-up form for user input)\n",
        "            # For now, just a placeholder for editing functionality\n",
        "            st.info(\"Edit functionality will go here.\")\n",
        "    else:\n",
        "        st.write(\"No data available for editing yet.\")\n",
        "\n",
        "# Streamlit App Main Logic\n",
        "def main():\n",
        "    st.title(\"BIC Bank Financial Data Processing\")\n",
        "    \n",
        "    # Step 5: Upload and Extract Data from PDF\n",
        "    extracted_data = upload_and_extract_data()\n",
        "\n",
        "    # Step 6: Display and Edit Existing Data from Database\n",
        "    if extracted_data is not None:\n",
        "        display_and_edit_data()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
